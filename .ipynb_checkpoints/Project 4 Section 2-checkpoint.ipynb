{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run helpers.py\n",
    "%run helpers-Copy1.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this section i will be attempting to try and predict salary based on other features such as title, locations etc\n",
    "\n",
    "I will be creating dummies out of those features and applying two models to better understand which feature best predicts salary\n",
    "\n",
    "The two Models are Linear Regression and Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading up both the cleaned data and the dummies:\n",
    "dummies=pd.read_excel('./dummies.xls')\n",
    "data=pd.read_excel('./cleaned.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'area', u'class', u'company', u'date', u'description', u'job_id',\n",
       "       u'level', u'location', u'salary', u'sub_class', u'title', u'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4335, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4335 entries, 0 to 6125\n",
      "Data columns (total 12 columns):\n",
      "area           4335 non-null object\n",
      "class          4335 non-null object\n",
      "company        4335 non-null object\n",
      "date           4335 non-null datetime64[ns]\n",
      "description    4335 non-null object\n",
      "job_id         4335 non-null int64\n",
      "level          4335 non-null object\n",
      "location       4335 non-null object\n",
      "salary         4335 non-null int64\n",
      "sub_class      4335 non-null object\n",
      "title          4335 non-null object\n",
      "type           4335 non-null object\n",
      "dtypes: datetime64[ns](1), int64(2), object(9)\n",
      "memory usage: 440.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>class</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>job_id</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>sub_class</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Southern Suburbs &amp; Logan</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>Opus Recruitment Solutions</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>DATA SCIENCE SUPERSTARS\\r\\n\\r\\nMODERN OFFICES\\...</td>\n",
       "      <td>35131268</td>\n",
       "      <td>normalJob</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>384</td>\n",
       "      <td>Database Development &amp; Administration</td>\n",
       "      <td>Data Science Leads</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Shore &amp; Northern Beaches</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>Spark Recruitment</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>Take ownership for the strategic development o...</td>\n",
       "      <td>35130098</td>\n",
       "      <td>normalJob</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>576</td>\n",
       "      <td>Product Management &amp; Development</td>\n",
       "      <td>Product Manager - Big Data / Data Analytics</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBD, Inner West &amp; Eastern Suburbs</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>2XM Technology Pty Ltd</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>Data Solution Architect required to work on a ...</td>\n",
       "      <td>35129596</td>\n",
       "      <td>normalJob</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>615</td>\n",
       "      <td>Architects</td>\n",
       "      <td>Big Data Solution Architect</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBD &amp; Inner Suburbs</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Employment Office</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>Are you an experienced Surveyor looking for an...</td>\n",
       "      <td>35131526</td>\n",
       "      <td>normalJob</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>269</td>\n",
       "      <td>Project Engineering</td>\n",
       "      <td>Surveyor Data Manager</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBD &amp; Inner Suburbs</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Employment Office</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>Are you an experienced Surveyor looking for an...</td>\n",
       "      <td>35131487</td>\n",
       "      <td>normalJob</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>269</td>\n",
       "      <td>Civil/Structural Engineering</td>\n",
       "      <td>Surveyor Data Manager</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                area                                   class  \\\n",
       "0           Southern Suburbs & Logan  Information & Communication Technology   \n",
       "1     North Shore & Northern Beaches  Information & Communication Technology   \n",
       "2  CBD, Inner West & Eastern Suburbs  Information & Communication Technology   \n",
       "3                CBD & Inner Suburbs                             Engineering   \n",
       "4                CBD & Inner Suburbs                             Engineering   \n",
       "\n",
       "                      company       date  \\\n",
       "0  Opus Recruitment Solutions 2017-12-21   \n",
       "1           Spark Recruitment 2017-12-21   \n",
       "2      2XM Technology Pty Ltd 2017-12-21   \n",
       "3           Employment Office 2017-12-21   \n",
       "4           Employment Office 2017-12-21   \n",
       "\n",
       "                                         description    job_id      level  \\\n",
       "0  DATA SCIENCE SUPERSTARS\\r\\n\\r\\nMODERN OFFICES\\...  35131268  normalJob   \n",
       "1  Take ownership for the strategic development o...  35130098  normalJob   \n",
       "2  Data Solution Architect required to work on a ...  35129596  normalJob   \n",
       "3  Are you an experienced Surveyor looking for an...  35131526  normalJob   \n",
       "4  Are you an experienced Surveyor looking for an...  35131487  normalJob   \n",
       "\n",
       "    location  salary                              sub_class  \\\n",
       "0     Sydney     384  Database Development & Administration   \n",
       "1     Sydney     576       Product Management & Development   \n",
       "2     Sydney     615                             Architects   \n",
       "3  Melbourne     269                    Project Engineering   \n",
       "4  Melbourne     269           Civil/Structural Engineering   \n",
       "\n",
       "                                         title       type  \n",
       "0                           Data Science Leads  Full Time  \n",
       "1  Product Manager - Big Data / Data Analytics  Full Time  \n",
       "2                  Big Data Solution Architect  Full Time  \n",
       "3                        Surveyor Data Manager  Full Time  \n",
       "4                        Surveyor Data Manager  Full Time  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print data.shape\n",
    "print data.info()\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4335, 103)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4335 entries, 0 to 4334\n",
      "Columns: 103 entries, class_Accounting to area_Western Suburbs & Ipswich\n",
      "dtypes: int64(103)\n",
      "memory usage: 3.4 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_Accounting</th>\n",
       "      <th>class_Administration &amp; Office Support</th>\n",
       "      <th>class_Advertising, Arts &amp; Media</th>\n",
       "      <th>class_Banking &amp; Financial Services</th>\n",
       "      <th>class_CEO &amp; General Management</th>\n",
       "      <th>class_Call Centre &amp; Customer Service</th>\n",
       "      <th>class_Community Services &amp; Development</th>\n",
       "      <th>class_Construction</th>\n",
       "      <th>class_Consulting &amp; Strategy</th>\n",
       "      <th>class_Design &amp; Architecture</th>\n",
       "      <th>...</th>\n",
       "      <th>area_Northern Suburbs</th>\n",
       "      <th>area_Northern Suburbs &amp; Joondalup</th>\n",
       "      <th>area_Parramatta &amp; Western Suburbs</th>\n",
       "      <th>area_Rockingham &amp; Kwinana</th>\n",
       "      <th>area_Ryde &amp; Macquarie Park</th>\n",
       "      <th>area_South West &amp; M5 Corridor</th>\n",
       "      <th>area_Southern Suburbs &amp; Logan</th>\n",
       "      <th>area_Southern Suburbs &amp; Sutherland Shire</th>\n",
       "      <th>area_Western Suburbs</th>\n",
       "      <th>area_Western Suburbs &amp; Ipswich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_Accounting  class_Administration & Office Support  \\\n",
       "0                 0                                      0   \n",
       "1                 0                                      0   \n",
       "2                 0                                      0   \n",
       "3                 0                                      0   \n",
       "4                 0                                      0   \n",
       "\n",
       "   class_Advertising, Arts & Media  class_Banking & Financial Services  \\\n",
       "0                                0                                   0   \n",
       "1                                0                                   0   \n",
       "2                                0                                   0   \n",
       "3                                0                                   0   \n",
       "4                                0                                   0   \n",
       "\n",
       "   class_CEO & General Management  class_Call Centre & Customer Service  \\\n",
       "0                               0                                     0   \n",
       "1                               0                                     0   \n",
       "2                               0                                     0   \n",
       "3                               0                                     0   \n",
       "4                               0                                     0   \n",
       "\n",
       "   class_Community Services & Development  class_Construction  \\\n",
       "0                                       0                   0   \n",
       "1                                       0                   0   \n",
       "2                                       0                   0   \n",
       "3                                       0                   0   \n",
       "4                                       0                   0   \n",
       "\n",
       "   class_Consulting & Strategy  class_Design & Architecture  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "                ...                area_Northern Suburbs  \\\n",
       "0               ...                                    0   \n",
       "1               ...                                    0   \n",
       "2               ...                                    0   \n",
       "3               ...                                    0   \n",
       "4               ...                                    0   \n",
       "\n",
       "   area_Northern Suburbs & Joondalup  area_Parramatta & Western Suburbs  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  0   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  0   \n",
       "\n",
       "   area_Rockingham & Kwinana  area_Ryde & Macquarie Park  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   area_South West & M5 Corridor  area_Southern Suburbs & Logan  \\\n",
       "0                              0                              1   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   area_Southern Suburbs & Sutherland Shire  area_Western Suburbs  \\\n",
       "0                                         0                     0   \n",
       "1                                         0                     0   \n",
       "2                                         0                     0   \n",
       "3                                         0                     0   \n",
       "4                                         0                     0   \n",
       "\n",
       "   area_Western Suburbs & Ipswich  \n",
       "0                               0  \n",
       "1                               0  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print dummies.shape\n",
    "print dummies.info()\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Creation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I am going to use the dummies that already exist and creat two new dummies:\n",
    "\n",
    "1)First i am going to make a dummy for data science title/roles and make it my 'y'/target variable because this is what we want\n",
    "predict and understand what feature can helps determine a data science role/title\n",
    "\n",
    "2)Secondly i am going to creat a dummy of description and add it back to the dummies for modelling and analysis the reason i didn't add in the previous section when making the dummies file is because i want to be able to tweak it and see which variation of description gives the best results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using these to get rid of unnecessary elements\n",
    "letters=string.letters\n",
    "numbers=string.digits\n",
    "elements=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer#Stemmer to stem the words\n",
    "lan_stem = LancasterStemmer()\n",
    "\n",
    "lem=[]\n",
    "for item in data['title']:\n",
    "    r=unicodedata.normalize('NFKD', item).encode('ascii','ignore')#converting unicode to string\n",
    "    lemm=r.split(' ')#splitting each string into individual words\n",
    "    for n,it in enumerate(lemm):\n",
    "        # removing the punctuation and numbers\n",
    "        all=string.maketrans('','')\n",
    "        noelements=it.translate(all, elements)\n",
    "        lemm[n]=lan_stem.stem(noelements.lower())\n",
    "\n",
    "    str_list = filter(None, lemm)#removing empty spaces from each list\n",
    "    lem.append(str_list)\n",
    "\n",
    "#joining them back together after stemming and cleaning    \n",
    "for n,item in enumerate(lem):\n",
    "    str1 = ' '.join(item)\n",
    "    lem[n]=str1\n",
    "    \n",
    "data['title_2']=lem#equating it to a new column in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "busy analyst    184\n",
      "project man      91\n",
      "busy develop     87\n",
      "man account      84\n",
      "develop man      82\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Setting the vectorizer just like we would set a model which will remove useless words\n",
    "#and will look for pairs of words in each value\n",
    "cvec = CountVectorizer(stop_words = \"english\",ngram_range=(2,2))\n",
    "\n",
    "#Fitting the vectorizer on title_2 our stemmed titles\n",
    "cvec.fit(data['title_2'])\n",
    "\n",
    "#making a dataframe out of it\n",
    "X_train = pd.DataFrame(cvec.transform(data[\"title_2\"]).todense(),\n",
    "                     columns = cvec.get_feature_names())\n",
    "\n",
    "words_counts = X_train.sum(axis=0)\n",
    "print words_counts.sort_values(ascending = False)['dat sci']#number of data science titles which is very small\n",
    "print words_counts.sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is all the data science title dummies \n",
    "y=X_train['dat sci']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description column cleaning to make a dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exactly like Title_2 but slightly different in the ngram_range\n",
    "\n",
    "lem2=[]\n",
    "for item in data['description']:\n",
    "    r=unicodedata.normalize('NFKD', item).encode('ascii','ignore')\n",
    "    lemm=r.split(' ')\n",
    "    for n,it in enumerate(lemm):\n",
    "        all=string.maketrans('','')\n",
    "        noelements=it.translate(all, elements)\n",
    "        lemm[n]=lan_stem.stem(noelements.lower())\n",
    "\n",
    "    str_list = filter(None, lemm)\n",
    "    lem2.append(str_list)\n",
    "\n",
    "for n,item in enumerate(lem2):\n",
    "    str1 = ' '.join(item)\n",
    "    lem2[n]=str1\n",
    "    \n",
    "data['description_2']=lem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_opportun    940\n",
       "word_join        862\n",
       "word_man         822\n",
       "word_team        792\n",
       "word_expery      748\n",
       "word_work        739\n",
       "word_lead        709\n",
       "word_busy        701\n",
       "word_rol         693\n",
       "word_ar          554\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Setting the vectorizer just like we would set a model and looking for single words\n",
    "cvec = CountVectorizer(stop_words = \"english\",ngram_range=(1,1))\n",
    "\n",
    "#Fitting the vectorizer on the cleaned description data\n",
    "cvec.fit(data['description_2'])\n",
    "\n",
    "#making a dataframe\n",
    "D_train = pd.DataFrame(cvec.transform(data[\"description_2\"]).todense(),\n",
    "                     columns = cvec.get_feature_names())\n",
    "\n",
    "#adding a prefix to make it easier to differentiate between the dummies\n",
    "D_train=D_train.add_prefix('word_')\n",
    "\n",
    "words_counts = D_train.sum(axis=0)\n",
    "words_counts.sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the description dummy dataframe to dummies(which i loaded up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies=pd.concat([dummies,D_train,data.salary],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4335 entries, 0 to 4334\n",
      "Columns: 3891 entries, class_Accounting to salary\n",
      "dtypes: int64(3891)\n",
      "memory usage: 128.7 MB\n"
     ]
    }
   ],
   "source": [
    "dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropping these words because theyu will skew the models heavily and because we are search for data science related terms\n",
    "dropping=['word_dat','word_sci']\n",
    "dummies.drop(dropping, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dummies.drop(['salary'],axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4335 entries, 0 to 4334\n",
      "Columns: 3889 entries, class_Accounting to salary\n",
      "dtypes: int64(3889)\n",
      "memory usage: 128.7 MB\n"
     ]
    }
   ],
   "source": [
    "dummies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After checking the number of 1s(26) and 0s(4309) clearly there is a class balance issue which is why the baseline is at 0.99\n",
    "\n",
    "So before any Modelling i will be Upsampling the Y-variable and X-Variable/Predictors(dummies) in order to remove the class imbalance. The reasoning behind this is beacuse we want to determine what features have impact in determining the role/title of data science. not to predict perse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994002306805\n",
      "0    4309\n",
      "1      26\n",
      "Name: dat sci, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "baseline=1-np.mean(y)\n",
    "print baseline\n",
    "print y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335\n",
      "4335\n"
     ]
    }
   ],
   "source": [
    "# checking to see if the len is the same which it is and should be:\n",
    "print len(y)\n",
    "print len(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm going to add the Y and X(dummies) together because it is the easiest way to upsample\n",
    "#concatenating them along the columns\n",
    "dummies=pd.concat([dummies,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4309\n",
       "1      26\n",
       "Name: dat sci, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies['dat sci'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All the code here was stright up copied from the resampling website you showed me and i understand exactly what it is doing\n",
    "\n",
    "from sklearn.utils import resample\n",
    "#dividing the 0s and 1s of ['dat sci'](data science) into seperate dataframes to upsample the 1s(minority)\n",
    "df_majority = dummies[dummies['dat sci']==0]\n",
    "\n",
    "df_minority = dummies[dummies['dat sci']==1]\n",
    "\n",
    "# Upsampling minority (1s)class by the same amount same the majority(0s)\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=4309,    # to match majority class\n",
    "                                 random_state=123)\n",
    "\n",
    "#recombining the upsampled class with the majority (along the index) and now both classes(0s and 1s) should be the same number\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled], axis=0)\n",
    "df_upsampled.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8618, 3890)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8618 entries, 0 to 8617\n",
      "Columns: 3890 entries, class_Accounting to dat sci\n",
      "dtypes: int64(3890)\n",
      "memory usage: 255.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print df_upsampled.shape\n",
    "print df_upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1    4309\n",
      "0    4309\n",
      "Name: dat sci, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking the upsampled baseline \n",
    "baseline=1-np.mean(df_upsampled['dat sci'])\n",
    "print baseline\n",
    "print df_upsampled['dat sci'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "X = df_upsampled.drop('dat sci', axis=1)\n",
    "y = df_upsampled['dat sci']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999071710374\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set\n",
    "prediction = model.predict(X)\n",
    " \n",
    "# How's our accuracy without cross validation\n",
    "print accuracy_score(y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98491879  0.99767981  0.99767981  0.99825986  0.99883856]\n",
      "0.995474588071\n"
     ]
    }
   ],
   "source": [
    "#Predicting using cross validation of 5 \n",
    "predictions = cross_val_predict(lr, X, y,cv=5)\n",
    "score  =  cross_val_score(lr, X, y,cv=5)\n",
    "\n",
    "print score\n",
    "print accuracy_score(y, predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#to see how many columns have the same coefficients:\n",
    "print len(model.coef_)-len(Counter(model.coef_).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_divid                     2.034905\n",
       "word_onsit                     1.876597\n",
       "word_fund                      1.831387\n",
       "word_telecommun                1.769817\n",
       "word_machin                    1.767477\n",
       "word_problem                   1.760585\n",
       "word_seen                      1.748971\n",
       "word_bree                      1.747193\n",
       "class_Consulting & Strategy    1.746536\n",
       "word_insight                   1.644414\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dateframe for the coefficients and there X predictors:\n",
    "# and sorting them to see which is the most impactful\n",
    "logic_coef=pd.DataFrame(model.coef_,columns=X.columns)\n",
    "logic_coef=logic_coef.abs()\n",
    "logic_coef.sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 1</th>\n",
       "      <th>predicted 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>4309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>39</td>\n",
       "      <td>4270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 1  predicted 0\n",
       "actual 1         4309            0\n",
       "actual 0           39         4270"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a confusion matrix give to me by yourself and i do understand how it works\n",
    "from sklearn.metrics import confusion_matrix\n",
    "my_matrix = np.array(confusion_matrix(y, predictions, labels=[1,0]))\n",
    "my_confusion_matrix = pd.DataFrame(my_matrix, index=['actual 1', 'actual 0'], columns=['predicted 1', 'predicted 0'])\n",
    "my_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Modelling with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "X = df_upsampled.drop('dat sci', axis=1)\n",
    "y = df_upsampled['dat sci']\n",
    "\n",
    "\n",
    "# criterion: splitting decision function (discussed later), can be 'gini' or 'entropy'\n",
    "# max_depth: the maximum number of hierarchical decision nodes (how \"deep\" the tree is built)\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='gini',\n",
    "                                    max_depth=None)\n",
    "\n",
    "regressor = DecisionTreeRegressor(criterion='mse',\n",
    "                                  max_depth=5)\n",
    "\n",
    "#REGRESSION\n",
    "# regress= regressor.fit(X, Y)\n",
    "\n",
    "# Y_pred = regress.predict(X)\n",
    "# score  =  regress.score(X, y)\n",
    "\n",
    "\n",
    "#CLASSIFICATION\n",
    "classer= classifier.fit(X, y)\n",
    "\n",
    "Y_pred = classer.predict(X)\n",
    "score  =  classer.score(X, y)\n",
    "\n",
    "\n",
    "# decision trees can give us feature importances. the higher the number the more important\n",
    "feature_importances = classer.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#to see how many columns have the same coefficients:\n",
    "print len(feature_importances)-len(Counter(feature_importances).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary                                          0.284603\n",
       "class_Accounting                                0.114373\n",
       "class_Consulting & Strategy                     0.077434\n",
       "word_correl                                     0.074069\n",
       "word_bree                                       0.070579\n",
       "class_Information & Communication Technology    0.063492\n",
       "word_insight                                    0.051059\n",
       "word_analyst                                    0.021768\n",
       "class_Construction                              0.018238\n",
       "word_work                                       0.011265\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dateframe for the coefficients and there X predictors:\n",
    "# and sorting them to see which is the most impactful\n",
    "trees_coef=pd.DataFrame([feature_importances], columns=X.columns)\n",
    "trees_coef=trees_coef.abs()\n",
    "trees_coef.sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 1</th>\n",
       "      <th>predicted 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>4309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>0</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 1  predicted 0\n",
       "actual 1         4309            0\n",
       "actual 0            0         4309"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a confusion matrix give to me by yourself and i do understand how it works\n",
    "from sklearn.metrics import confusion_matrix\n",
    "my_matrix = np.array(confusion_matrix(y, Y_pred, labels=[1,0]))\n",
    "my_confusion_matrix = pd.DataFrame(my_matrix, index=['actual 1', 'actual 0'], columns=['predicted 1', 'predicted 0'])\n",
    "my_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Both models are excellent in classifying and determining whether a particular role is a data science role or not based on the features fed into it\n",
    "However the goal which is to the determine the factors/ features that make a data science role a data science role and clearly from the previous code output we can see that salary and certain other features are heaviest in determining a data science role\n",
    "therefore these features are important especially if one wants to know whether a particulat role is a data science role or not\n",
    "\n",
    "i actually realise how this working now and am happy with my results\n",
    "\n",
    "Thank you Lauren this was actually a pretty damn good project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
